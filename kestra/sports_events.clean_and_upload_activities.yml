id: clean_and_upload_activities
namespace: sports_events

inputs:
  - id: activities_raw_file
    type: STRING

tasks:
  
  # 1. CLEAN ACTIVITIES (Python)
  - id: clean_activities_python
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: ghcr.io/kestra-io/pydata:latest
    beforeCommands:
      - pip install --no-cache-dir unidecode

    script: |
      import pandas as pd
      import json

      # Load JSONL file
      with open("{{ inputs.activities_raw_file }}", "r") as f:
          lines = f.read().strip().split("\n")
          raw_list = [json.loads(line) for line in lines]

      raw_df = pd.DataFrame(raw_list)

      # Parse docs
      def safe_parse(x):
          if isinstance(x, dict):
              return x
          if isinstance(x, str):
              return json.loads(x)
          raise ValueError(f"Unexpected type in _airbyte_data: {type(x)}")

      raw_df["_airbyte_data"] = raw_df["_airbyte_data"].apply(safe_parse)
      df = pd.json_normalize(raw_df["_airbyte_data"])

      # Normalize columns
      df.columns = (
          df.columns
            .str.strip()
            .str.lower()
            .str.normalize('NFKD')
            .str.encode('ascii', errors='ignore')
            .str.decode('utf-8')
            .str.replace(' ', '_')
      )

      # Cleaning / typing
      if "date_activities" in df.columns:
          df["date_activities"] = pd.to_datetime(df["date_activities"], errors="coerce")

      if "duree_min" in df.columns:
          df["duree_min"] = pd.to_numeric(df["duree_min"], errors="coerce")

      df = df[df["employee_id"].notnull()]

      # Save cleaned CSV
      df.to_csv("activities_clean.csv", index=False)

    inputFiles: {}
    outputFiles:
      - "activities_clean.csv"

 
  # 2. UPLOAD CLEAN FILE TO S3
 
  - id: upload_clean_activities
    type: io.kestra.plugin.aws.s3.Upload
    from: "{{ outputs.clean_activities_python.outputFiles['activities_clean.csv'] }}"
    bucket: sport-data-raw
    key: "clean/activities/activities_clean.csv"
    accessKeyId: "redacted"
    secretKeyId: "redacted"
    region: "eu-west-3"


# TRIGGER â€” start after Flow 1 (extract_activities_raw_from_s3)

triggers:
  - id: trigger_after_extract_activities
    type: io.kestra.plugin.core.trigger.Flow
    preconditions:
      id: activities_extract_done
      flows:
        - namespace: sports_events
          flowId: extract_activities_raw_from_s3
          states: [SUCCESS]
    inputs:
      activities_raw_file: "{{ outputs.download_activities_raw.uri }}"
